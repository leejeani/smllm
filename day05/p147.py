import streamlit as st

from llm.MyLLM import getChatOpenAI

st.set_page_config(page_title="ğŸ¦œğŸ”— ë­ë“ ì§€ ì§ˆë¬¸í•˜ì„¸ìš”~ ")
st.title('ğŸ¦œğŸ”— ë­ë“ ì§€ ì§ˆë¬¸í•˜ì„¸ìš”~ ')

def generate_response(input_text):  #llmì´ ë‹µë³€ ìƒì„±
    llm = getChatOpenAI()
    st.info(llm.predict(input_text))

with st.form('Question'):
    text = st.text_area('ì§ˆë¬¸ ì…ë ¥:', 'What types of text models does OpenAI provide?') #ì²« í˜ì´ì§€ê°€ ì‹¤í–‰ë  ë•Œ ë³´ì—¬ì¤„ ì§ˆë¬¸
    submitted = st.form_submit_button('ë³´ë‚´ê¸°')
    generate_response(text)